{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "with open('dataset/sw.txt') as file:\n",
    "    stop_words = []\n",
    "    for item in file:\n",
    "        stop_words.append(item.rstrip('\\n'))\n",
    "\n",
    "titles = []\n",
    "texts = []\n",
    "unigram = []\n",
    "bigram = []\n",
    "epsilon = 0.000000000001\n",
    "epsilon2 = 0.00000001\n",
    "classes_dict = dict()\n",
    "classes = []\n",
    "classes_words_num_dict = dict()\n",
    "classes_phrases_num_dict = dict()\n",
    "Lambda1 = 0.8\n",
    "Lambda2 = 0.2\n",
    "unknown_word_hits = 0\n",
    "unknown_phrase_hits = 0\n",
    "\n",
    "word_each_class_num = dict()\n",
    "phrase_each_class_num = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = pd.read_csv('dataset/reviews_train.csv')\n",
    "texts = pure_data[\"Review\"].dropna().values\n",
    "titles = pure_data[\"Label\"].dropna().values\n",
    "\n",
    "for title in titles:\n",
    "    classes_dict[title] = classes_dict.get(title, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 102, 'neg': 77}\n",
      "dict_keys(['pos', 'neg'])\n"
     ]
    }
   ],
   "source": [
    "train_doc_size = len(titles)\n",
    "classes = classes_dict.keys()\n",
    "print(classes_dict)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(titles)):\n",
    "    text = texts[j]\n",
    "    title = titles[j]\n",
    "    words = text.split(\" \")\n",
    "    counter = dict()\n",
    "    counter2 = dict()\n",
    "\n",
    "    ii = 0\n",
    "    word2 = \"\"\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in stop_words or word2 in stop_words:\n",
    "            continue\n",
    "        ii += 1\n",
    "        counter[word] = counter.get(word, 0.0) + 1.0\n",
    "        phrase = word2 + word\n",
    "        counter2[phrase] = counter2.get(phrase, 0.0) + 1.0\n",
    "        if word_each_class_num.get(word, 0) == 0:\n",
    "            word_each_class_num[word] = dict()\n",
    "\n",
    "        word_each_class_num[word][title] = word_each_class_num[word].get(title, 0) + 1\n",
    "\n",
    "        if phrase_each_class_num.get(phrase, 0) == 0:\n",
    "            phrase_each_class_num[phrase] = dict()\n",
    "\n",
    "        phrase_each_class_num[phrase][title] = phrase_each_class_num[phrase].get(title, 0) + 1\n",
    "\n",
    "        word2 = word\n",
    "\n",
    "    counter['words_number'] = ii\n",
    "    counter2['phrases_number'] = ii\n",
    "    unigram.append(counter)\n",
    "    bigram.append(counter2)\n",
    "\n",
    "all_words_num = 0\n",
    "all_phrases_num = 0\n",
    "for j in range(train_doc_size):\n",
    "    all_words_num += unigram[j]['words_number']\n",
    "    all_phrases_num += bigram[j]['phrases_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = []\n",
    "test_texts = []\n",
    "test_answers = []\n",
    "\n",
    "\n",
    "pure_data_test = pd.read_csv('dataset/reviews_test.csv')\n",
    "test_texts = pure_data_test[\"Review\"].dropna().values\n",
    "test_titles = pure_data_test[\"Label\"].dropna().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_prob(wordd):\n",
    "    word_repetition = 0.0\n",
    "    for i in range(train_doc_size):\n",
    "        word_repetition += unigram[i].get(wordd, epsilon2)\n",
    "    return word_repetition / all_words_num\n",
    "\n",
    "\n",
    "def phrase_prob(phrasee):\n",
    "    phrase_repetition = 0.0\n",
    "    for i in range(train_doc_size):\n",
    "        phrase_repetition += bigram[i].get(phrasee, epsilon2)\n",
    "    return phrase_repetition / all_phrases_num\n",
    "\n",
    "\n",
    "def unigram_class_words_num(_class):\n",
    "    class_words_num = 0.0\n",
    "    for ii in range(train_doc_size):\n",
    "        if titles[ii] == _class:\n",
    "            class_words_num += unigram[ii]['words_number']\n",
    "    return class_words_num\n",
    "\n",
    "\n",
    "def bigram_class_phrases_num(_class):\n",
    "    class_phrases_num = 0.0\n",
    "    for ii in range(train_doc_size):\n",
    "        if titles[ii] == _class:\n",
    "            class_phrases_num += bigram[ii]['phrases_number']\n",
    "    return class_phrases_num\n",
    "\n",
    "\n",
    "for _class_ in classes:\n",
    "    classes_words_num_dict[_class_] = unigram_class_words_num(_class_)\n",
    "    classes_phrases_num_dict[_class_] = bigram_class_phrases_num(_class_)\n",
    "\n",
    "\n",
    "def prob_word_class(word, classs):\n",
    "    global unknown_word_hits\n",
    "    if word_each_class_num.get(word, 0) == 0:\n",
    "        unknown_word_hits += 1\n",
    "        return epsilon\n",
    "    if word_each_class_num[word].get(classs, 0) == 0:\n",
    "        return epsilon\n",
    "    else:\n",
    "        return word_each_class_num[word][classs]/classes_words_num_dict[classs]\n",
    "\n",
    "\n",
    "def prob_phrase_class(word1, word2, classs):\n",
    "    global unknown_phrase_hits\n",
    "    phrase = word2+word1\n",
    "    if phrase_each_class_num.get(phrase, -1) == -1:\n",
    "        unknown_phrase_hits += 1\n",
    "        return epsilon2\n",
    "    if phrase_each_class_num[phrase].get(classs, -1) == -1:\n",
    "        return epsilon2\n",
    "    else:\n",
    "        if word_each_class_num.get(word2, -1) == -1:\n",
    "            unknown_phrase_hits += 1\n",
    "            return epsilon2\n",
    "        if word_each_class_num[word2].get(classs, -1) == -1:\n",
    "            return epsilon2\n",
    "        else:\n",
    "            return phrase_each_class_num[phrase][classs]/word_each_class_num[word2][classs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_text in test_texts:\n",
    "    test_text_words = test_text.split(\" \")\n",
    "    best_prob = 0.0\n",
    "    class_answer = \"\"\n",
    "    curr = 0\n",
    "    for _classs in classes:\n",
    "        unigram_class_prob = classes_words_num_dict[_classs]/all_words_num\n",
    "        bigram_class_prob = classes_phrases_num_dict[_classs] / all_phrases_num\n",
    "        # unigram_class_prob = classes_dict[_classs] / train_doc_size\n",
    "        # bigram_class_prob = classes_dict[_classs] / train_doc_size\n",
    "        unigram_sigma = 0.0\n",
    "        bigram_sigma = 0.0\n",
    "        wrd2 = \"\"\n",
    "        for wrd in test_text_words:\n",
    "            wrd = wrd.lower()\n",
    "            if wrd in stop_words or wrd2 in stop_words:\n",
    "                continue\n",
    "            unigram_sigma += math.log10(prob_word_class(wrd, _classs))\n",
    "            phrase = wrd2+wrd\n",
    "            bigram_sigma += math.log10(prob_phrase_class(wrd, wrd2, _classs))\n",
    "            wrd2 = wrd\n",
    "        unigram_prob = math.log10(unigram_class_prob) + unigram_sigma\n",
    "        bigram_prob = math.log10(bigram_class_prob) + bigram_sigma\n",
    "        prob = Lambda1 * unigram_prob + Lambda2 * bigram_prob\n",
    "\n",
    "        if curr == 0:\n",
    "            best_prob = prob\n",
    "            class_answer = _classs\n",
    "        elif prob > best_prob:\n",
    "            best_prob = prob\n",
    "            class_answer = _classs\n",
    "        curr += 1\n",
    "\n",
    "    test_answers.append(class_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = dict()\n",
    "FP = dict()\n",
    "true_answers = 0\n",
    "for i in range(len(test_titles)):\n",
    "    if test_titles[i] == test_answers[i]:\n",
    "        true_answers += 1\n",
    "        TP[test_titles[i]] = TP.get(test_titles[i], 0) + 1\n",
    "    else:\n",
    "        if FP.get(test_titles[i], 0) == 0:\n",
    "            FP[test_titles[i]] = dict()\n",
    "        FP[test_titles[i]][test_answers[i]] = FP[test_titles[i]].get(test_answers[i], 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_doc_size:  20\n",
      "unknown word hits is:  902\n",
      "unknown phrase hits is:  1752\n",
      "Total Accuracy is :  60.0\n",
      "Recall         Precision     F-measure\n",
      "0.7777         0.5384          0.6362              pos\n",
      "0.4545         0.7142          0.5554              neg\n"
     ]
    }
   ],
   "source": [
    "print(\"test_doc_size: \", len(test_titles))\n",
    "print(\"unknown word hits is: \", unknown_word_hits)\n",
    "print(\"unknown phrase hits is: \", unknown_phrase_hits)\n",
    "print(\"Total Accuracy is : \", true_answers/len(test_titles)*100)\n",
    "recall = dict()\n",
    "for class_ in classes:\n",
    "    TPP = TP[class_]\n",
    "    keys = FP[class_].keys()\n",
    "    FPP = 0\n",
    "    for key in keys:\n",
    "        FPP += FP[class_][key]\n",
    "    recall[class_] = TPP/(TPP+FPP)\n",
    "\n",
    "precision = dict()\n",
    "for class_ in classes:\n",
    "    TPP = TP[class_]\n",
    "    FPP = 0\n",
    "    for cls in classes:\n",
    "        if cls != class_:\n",
    "            FPP += FP[cls].get(class_, 0)\n",
    "    precision[class_] = TPP/(TPP+FPP)\n",
    "\n",
    "print('Recall         Precision     F-measure')\n",
    "for class_ in classes:\n",
    "    rcal = int(recall[class_]*10000)\n",
    "    prcsion = int(precision[class_]*10000)\n",
    "    rcal = rcal/10000\n",
    "    prcsion = prcsion/10000\n",
    "    fmeasure = int(2 * rcal * prcsion / (rcal + prcsion) * 10000)\n",
    "    fmeasure = fmeasure/10000\n",
    "    space = \" \" * (15-len(class_))\n",
    "    print(rcal, \"       \", prcsion, \"        \", fmeasure, space, class_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
